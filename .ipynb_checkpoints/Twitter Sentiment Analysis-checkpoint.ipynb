{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1Km2p7VaMur_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "wUYbjjH7Tbkb",
    "outputId": "0d4da154-4f95-4bf6-b03a-7e51b5aae973"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>569934458364813313</td>\n",
       "      <td>neutral</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cottopanama85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir followback</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 10:58:58 -0800</td>\n",
       "      <td>ohio,panama</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>568564006329434113</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaulBEsteves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united thanks for the help. Wish the phone re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 16:13:17 -0800</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>569643648910028801</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>runfixsteve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@usairways the. Worst. Ever. #dca #customerser...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 15:43:24 -0800</td>\n",
       "      <td>St. Augustine, Florida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>568864981917110272</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLChicosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@nrhodes85: look! Another apology. DO NOT FLY ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 12:09:15 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>568929299350179840</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JW_Blocker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@united you are by far the worst airline. 4 pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:24:49 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id  ...               user_timezone\n",
       "0      567900433542488064  ...      Atlantic Time (Canada)\n",
       "1      569989168903819264  ...  Central Time (US & Canada)\n",
       "2      568089179520954368  ...  Central Time (US & Canada)\n",
       "3      568928195581513728  ...      Atlantic Time (Canada)\n",
       "4      568594180014014464  ...  Eastern Time (US & Canada)\n",
       "...                   ...  ...                         ...\n",
       "10975  569934458364813313  ...                         NaN\n",
       "10976  568564006329434113  ...  Eastern Time (US & Canada)\n",
       "10977  569643648910028801  ...                         NaN\n",
       "10978  568864981917110272  ...                         NaN\n",
       "10979  568929299350179840  ...                         NaN\n",
       "\n",
       "[10980 rows x 12 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "tweet_data = pd.read_csv('/content/0000000000002747_training_twitter_x_y_train.csv')\n",
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "QP2Ng2FWTwp1",
    "outputId": "0311bd1c-3dad-4586-d292-5ca11ceaaadf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.098000e+04</td>\n",
       "      <td>10980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692169e+17</td>\n",
       "      <td>0.080965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.795438e+14</td>\n",
       "      <td>0.740303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675883e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685584e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694753e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698902e+17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  retweet_count\n",
       "count  1.098000e+04   10980.000000\n",
       "mean   5.692169e+17       0.080965\n",
       "std    7.795438e+14       0.740303\n",
       "min    5.675883e+17       0.000000\n",
       "25%    5.685584e+17       0.000000\n",
       "50%    5.694753e+17       0.000000\n",
       "75%    5.698902e+17       0.000000\n",
       "max    5.703106e+17      44.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TT3KrgJTUJ4S",
    "outputId": "cbde41f4-7d89-4500-ecdd-138a294166ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10949"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data[\"airline_sentiment_gold\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "KeLSQv_CT58j"
   },
   "outputs": [],
   "source": [
    "del tweet_data[\"tweet_id\"]\n",
    "del tweet_data[\"airline\"]\n",
    "del tweet_data[\"airline_sentiment_gold\"]\n",
    "del tweet_data[\"name\"]\n",
    "del tweet_data[\"negativereason_gold\"]\n",
    "del tweet_data[\"retweet_count\"]\n",
    "del tweet_data[\"tweet_coord\"]\n",
    "del tweet_data[\"tweet_location\"]\n",
    "del tweet_data[\"tweet_created\"]\n",
    "del tweet_data[\"user_timezone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "muVbIyKtUf7_",
    "outputId": "3c95b0b3-b155-4641-94fd-6608de0abed0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0          negative  @SouthwestAir I am scheduled for the morning, ...\n",
       "1          positive  @SouthwestAir seeing your workers time in and ...\n",
       "2          positive  @united Flew ORD to Miami and back and  had gr...\n",
       "3          negative     @SouthwestAir @dultch97 that's horse radish üò§üê¥\n",
       "4          negative  @united so our flight into ORD was delayed bec..."
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "0ttXJqZDuhQg",
    "outputId": "a9149c89-b645-41a9-ab8b-b1651e36b25d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir followback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united thanks for the help. Wish the phone re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>negative</td>\n",
       "      <td>@usairways the. Worst. Ever. #dca #customerser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>negative</td>\n",
       "      <td>@nrhodes85: look! Another apology. DO NOT FLY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united you are by far the worst airline. 4 pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0              negative  @SouthwestAir I am scheduled for the morning, ...\n",
       "1              positive  @SouthwestAir seeing your workers time in and ...\n",
       "2              positive  @united Flew ORD to Miami and back and  had gr...\n",
       "3              negative     @SouthwestAir @dultch97 that's horse radish üò§üê¥\n",
       "4              negative  @united so our flight into ORD was delayed bec...\n",
       "...                 ...                                                ...\n",
       "10975           neutral                            @AmericanAir followback\n",
       "10976          positive  @united thanks for the help. Wish the phone re...\n",
       "10977          negative  @usairways the. Worst. Ever. #dca #customerser...\n",
       "10978          negative  @nrhodes85: look! Another apology. DO NOT FLY ...\n",
       "10979          negative  @united you are by far the worst airline. 4 pl...\n",
       "\n",
       "[10980 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data = tweet_data.dropna()\n",
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjcSGf-SUv2L",
    "outputId": "b928a0e0-858c-45fe-da51-6e632cb017bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @SouthwestAir I am scheduled for the morning, ...\n",
       "1        @SouthwestAir seeing your workers time in and ...\n",
       "2        @united Flew ORD to Miami and back and  had gr...\n",
       "3           @SouthwestAir @dultch97 that's horse radish üò§üê¥\n",
       "4        @united so our flight into ORD was delayed bec...\n",
       "                               ...                        \n",
       "10975                              @AmericanAir followback\n",
       "10976    @united thanks for the help. Wish the phone re...\n",
       "10977    @usairways the. Worst. Ever. #dca #customerser...\n",
       "10978    @nrhodes85: look! Another apology. DO NOT FLY ...\n",
       "10979    @united you are by far the worst airline. 4 pl...\n",
       "Name: text, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list = tweet_data[\"text\"]\n",
    "tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoTaXjPJU9RI",
    "outputId": "d6d2bafd-14db-4159-c728-77cdce9ea6ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        negative\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        negative\n",
       "           ...   \n",
       "10975     neutral\n",
       "10976    positive\n",
       "10977    negative\n",
       "10978    negative\n",
       "10979    negative\n",
       "Name: airline_sentiment, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tweet_data[\"airline_sentiment\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "5lETPD9pjTmC"
   },
   "outputs": [],
   "source": [
    "def transform_y(sentiment):\n",
    "  if (sentiment.lower() == \"negative\"):\n",
    "    return 0\n",
    "  elif (sentiment.lower() == \"positive\"):\n",
    "    return 1\n",
    "  else:\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCYHsUsUjKrz",
    "outputId": "b43cc9c0-68d2-4d25-d091-0e9f8036068a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "10975    2\n",
       "10976    1\n",
       "10977    0\n",
       "10978    0\n",
       "10979    0\n",
       "Name: airline_sentiment, Length: 10980, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labelled = y.apply(transform_y)\n",
    "y_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "QhkSNH0wiH7G"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_tweets_list, test_tweets_list, y_train, y_test = train_test_split(tweets_list, y_labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_dN0S6-i0Y9",
    "outputId": "c55ba895-bab8-4e08-e451-fb5ed0d6c14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8235,)\n",
      "(2745,)\n",
      "(8235,)\n",
      "(2745,)\n"
     ]
    }
   ],
   "source": [
    "print(train_tweets_list.shape)\n",
    "print(test_tweets_list.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JurtzxWPindm",
    "outputId": "61e73704-4448-4719-b6af-f7e0e3845faf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333     @AmericanAir @sweetmel If weather is bad, woul...\n",
       "9692            @AmericanAir yes. He's in the next flight\n",
       "4617    @USAirways stuck on the ramp at DCA, US Air co...\n",
       "9124    @AmericanAir @dotnetnate Two hour wait for EXP...\n",
       "7737    @AmericanAir been @ airport 8hrs been told not...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JCnqquvi9M5",
    "outputId": "2cbf610f-6bde-4a63-dc22-01d42a476c1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6293    @AmericanAir are you guys intentionally trying...\n",
       "252     @JetBlue When I checked yesterday it looked li...\n",
       "1638                            @SouthwestAir 5 min away!\n",
       "466     @USAirways I will NEVER fly us airways or amer...\n",
       "1383    @united Shame that there's no flex to tickets ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gASAv7Pzi-0W",
    "outputId": "ac31d162-936d-4cfa-ab2d-a4c39fab2fc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333     0\n",
       "9692    2\n",
       "4617    0\n",
       "9124    0\n",
       "7737    0\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3If9TaBNjAYy",
    "outputId": "1065b09a-c151-445f-fbb0-d65bbab4539d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6293    0\n",
       "252     2\n",
       "1638    2\n",
       "466     0\n",
       "1383    0\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-4ntm-LVbYS",
    "outputId": "06ee515f-dfe1-4817-d51f-e33ebfb1cb99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> all\n",
      "    Downloading collection 'all'\n",
      "       | \n",
      "       | Downloading package abc to /root/nltk_data...\n",
      "       |   Unzipping corpora/abc.zip.\n",
      "       | Downloading package alpino to /root/nltk_data...\n",
      "       |   Unzipping corpora/alpino.zip.\n",
      "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
      "       |   Unzipping corpora/biocreative_ppi.zip.\n",
      "       | Downloading package brown to /root/nltk_data...\n",
      "       |   Unzipping corpora/brown.zip.\n",
      "       | Downloading package brown_tei to /root/nltk_data...\n",
      "       |   Unzipping corpora/brown_tei.zip.\n",
      "       | Downloading package cess_cat to /root/nltk_data...\n",
      "       |   Unzipping corpora/cess_cat.zip.\n",
      "       | Downloading package cess_esp to /root/nltk_data...\n",
      "       |   Unzipping corpora/cess_esp.zip.\n",
      "       | Downloading package chat80 to /root/nltk_data...\n",
      "       |   Unzipping corpora/chat80.zip.\n",
      "       | Downloading package city_database to /root/nltk_data...\n",
      "       |   Unzipping corpora/city_database.zip.\n",
      "       | Downloading package cmudict to /root/nltk_data...\n",
      "       |   Unzipping corpora/cmudict.zip.\n",
      "       | Downloading package comparative_sentences to\n",
      "       |     /root/nltk_data...\n",
      "       |   Unzipping corpora/comparative_sentences.zip.\n",
      "       | Downloading package comtrans to /root/nltk_data...\n",
      "       | Downloading package conll2000 to /root/nltk_data...\n",
      "       |   Unzipping corpora/conll2000.zip.\n",
      "       | Downloading package conll2002 to /root/nltk_data...\n",
      "       |   Unzipping corpora/conll2002.zip.\n",
      "       | Downloading package conll2007 to /root/nltk_data...\n",
      "       | Downloading package crubadan to /root/nltk_data...\n",
      "       |   Unzipping corpora/crubadan.zip.\n",
      "       | Downloading package dependency_treebank to /root/nltk_data...\n",
      "       |   Unzipping corpora/dependency_treebank.zip.\n",
      "       | Downloading package dolch to /root/nltk_data...\n",
      "       |   Unzipping corpora/dolch.zip.\n",
      "       | Downloading package europarl_raw to /root/nltk_data...\n",
      "       |   Unzipping corpora/europarl_raw.zip.\n",
      "       | Downloading package floresta to /root/nltk_data...\n",
      "       |   Unzipping corpora/floresta.zip.\n",
      "       | Downloading package framenet_v15 to /root/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v15.zip.\n",
      "       | Downloading package framenet_v17 to /root/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v17.zip.\n",
      "       | Downloading package gazetteers to /root/nltk_data...\n",
      "       |   Unzipping corpora/gazetteers.zip.\n",
      "       | Downloading package genesis to /root/nltk_data...\n",
      "       |   Unzipping corpora/genesis.zip.\n",
      "       | Downloading package gutenberg to /root/nltk_data...\n",
      "       |   Unzipping corpora/gutenberg.zip.\n",
      "       | Downloading package ieer to /root/nltk_data...\n",
      "       |   Unzipping corpora/ieer.zip.\n",
      "       | Downloading package inaugural to /root/nltk_data...\n",
      "       |   Unzipping corpora/inaugural.zip.\n",
      "       | Downloading package indian to /root/nltk_data...\n",
      "       |   Unzipping corpora/indian.zip.\n",
      "       | Downloading package jeita to /root/nltk_data...\n",
      "       | Downloading package kimmo to /root/nltk_data...\n",
      "       |   Unzipping corpora/kimmo.zip.\n",
      "       | Downloading package knbc to /root/nltk_data...\n",
      "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
      "       |   Unzipping corpora/lin_thesaurus.zip.\n",
      "       | Downloading package mac_morpho to /root/nltk_data...\n",
      "       |   Unzipping corpora/mac_morpho.zip.\n",
      "       | Downloading package machado to /root/nltk_data...\n",
      "       | Downloading package masc_tagged to /root/nltk_data...\n",
      "       | Downloading package moses_sample to /root/nltk_data...\n",
      "       |   Unzipping models/moses_sample.zip.\n",
      "       | Downloading package movie_reviews to /root/nltk_data...\n",
      "       |   Unzipping corpora/movie_reviews.zip.\n",
      "       | Downloading package names to /root/nltk_data...\n",
      "       |   Unzipping corpora/names.zip.\n",
      "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "       | Downloading package nps_chat to /root/nltk_data...\n",
      "       |   Unzipping corpora/nps_chat.zip.\n",
      "       | Downloading package omw to /root/nltk_data...\n",
      "       |   Unzipping corpora/omw.zip.\n",
      "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
      "       |   Unzipping corpora/opinion_lexicon.zip.\n",
      "       | Downloading package paradigms to /root/nltk_data...\n",
      "       |   Unzipping corpora/paradigms.zip.\n",
      "       | Downloading package pil to /root/nltk_data...\n",
      "       |   Unzipping corpora/pil.zip.\n",
      "       | Downloading package pl196x to /root/nltk_data...\n",
      "       |   Unzipping corpora/pl196x.zip.\n",
      "       | Downloading package ppattach to /root/nltk_data...\n",
      "       |   Unzipping corpora/ppattach.zip.\n",
      "       | Downloading package problem_reports to /root/nltk_data...\n",
      "       |   Unzipping corpora/problem_reports.zip.\n",
      "       | Downloading package propbank to /root/nltk_data...\n",
      "       | Downloading package ptb to /root/nltk_data...\n",
      "       |   Unzipping corpora/ptb.zip.\n",
      "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_1.zip.\n",
      "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_2.zip.\n",
      "       | Downloading package pros_cons to /root/nltk_data...\n",
      "       |   Unzipping corpora/pros_cons.zip.\n",
      "       | Downloading package qc to /root/nltk_data...\n",
      "       |   Unzipping corpora/qc.zip.\n",
      "       | Downloading package reuters to /root/nltk_data...\n",
      "       | Downloading package rte to /root/nltk_data...\n",
      "       |   Unzipping corpora/rte.zip.\n",
      "       | Downloading package semcor to /root/nltk_data...\n",
      "       | Downloading package senseval to /root/nltk_data...\n",
      "       |   Unzipping corpora/senseval.zip.\n",
      "       | Downloading package sentiwordnet to /root/nltk_data...\n",
      "       |   Unzipping corpora/sentiwordnet.zip.\n",
      "       | Downloading package sentence_polarity to /root/nltk_data...\n",
      "       |   Unzipping corpora/sentence_polarity.zip.\n",
      "       | Downloading package shakespeare to /root/nltk_data...\n",
      "       |   Unzipping corpora/shakespeare.zip.\n",
      "       | Downloading package sinica_treebank to /root/nltk_data...\n",
      "       |   Unzipping corpora/sinica_treebank.zip.\n",
      "       | Downloading package smultron to /root/nltk_data...\n",
      "       |   Unzipping corpora/smultron.zip.\n",
      "       | Downloading package state_union to /root/nltk_data...\n",
      "       |   Unzipping corpora/state_union.zip.\n",
      "       | Downloading package stopwords to /root/nltk_data...\n",
      "       |   Unzipping corpora/stopwords.zip.\n",
      "       | Downloading package subjectivity to /root/nltk_data...\n",
      "       |   Unzipping corpora/subjectivity.zip.\n",
      "       | Downloading package swadesh to /root/nltk_data...\n",
      "       |   Unzipping corpora/swadesh.zip.\n",
      "       | Downloading package switchboard to /root/nltk_data...\n",
      "       |   Unzipping corpora/switchboard.zip.\n",
      "       | Downloading package timit to /root/nltk_data...\n",
      "       |   Unzipping corpora/timit.zip.\n",
      "       | Downloading package toolbox to /root/nltk_data...\n",
      "       |   Unzipping corpora/toolbox.zip.\n",
      "       | Downloading package treebank to /root/nltk_data...\n",
      "       |   Unzipping corpora/treebank.zip.\n",
      "       | Downloading package twitter_samples to /root/nltk_data...\n",
      "       |   Unzipping corpora/twitter_samples.zip.\n",
      "       | Downloading package udhr to /root/nltk_data...\n",
      "       |   Unzipping corpora/udhr.zip.\n",
      "       | Downloading package udhr2 to /root/nltk_data...\n",
      "       |   Unzipping corpora/udhr2.zip.\n",
      "       | Downloading package unicode_samples to /root/nltk_data...\n",
      "       |   Unzipping corpora/unicode_samples.zip.\n",
      "       | Downloading package universal_treebanks_v20 to\n",
      "       |     /root/nltk_data...\n",
      "       | Downloading package verbnet to /root/nltk_data...\n",
      "       |   Unzipping corpora/verbnet.zip.\n",
      "       | Downloading package verbnet3 to /root/nltk_data...\n",
      "       |   Unzipping corpora/verbnet3.zip.\n",
      "       | Downloading package webtext to /root/nltk_data...\n",
      "       |   Unzipping corpora/webtext.zip.\n",
      "       | Downloading package wordnet to /root/nltk_data...\n",
      "       |   Unzipping corpora/wordnet.zip.\n",
      "       | Downloading package wordnet_ic to /root/nltk_data...\n",
      "       |   Unzipping corpora/wordnet_ic.zip.\n",
      "       | Downloading package words to /root/nltk_data...\n",
      "       |   Unzipping corpora/words.zip.\n",
      "       | Downloading package ycoe to /root/nltk_data...\n",
      "       |   Unzipping corpora/ycoe.zip.\n",
      "       | Downloading package rslp to /root/nltk_data...\n",
      "       |   Unzipping stemmers/rslp.zip.\n",
      "       | Downloading package maxent_treebank_pos_tagger to\n",
      "       |     /root/nltk_data...\n",
      "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "       | Downloading package universal_tagset to /root/nltk_data...\n",
      "       |   Unzipping taggers/universal_tagset.zip.\n",
      "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
      "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "       | Downloading package punkt to /root/nltk_data...\n",
      "       |   Unzipping tokenizers/punkt.zip.\n",
      "       | Downloading package book_grammars to /root/nltk_data...\n",
      "       |   Unzipping grammars/book_grammars.zip.\n",
      "       | Downloading package sample_grammars to /root/nltk_data...\n",
      "       |   Unzipping grammars/sample_grammars.zip.\n",
      "       | Downloading package spanish_grammars to /root/nltk_data...\n",
      "       |   Unzipping grammars/spanish_grammars.zip.\n",
      "       | Downloading package basque_grammars to /root/nltk_data...\n",
      "       |   Unzipping grammars/basque_grammars.zip.\n",
      "       | Downloading package large_grammars to /root/nltk_data...\n",
      "       |   Unzipping grammars/large_grammars.zip.\n",
      "       | Downloading package tagsets to /root/nltk_data...\n",
      "       |   Unzipping help/tagsets.zip.\n",
      "       | Downloading package snowball_data to /root/nltk_data...\n",
      "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
      "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "       | Downloading package word2vec_sample to /root/nltk_data...\n",
      "       |   Unzipping models/word2vec_sample.zip.\n",
      "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
      "       | Downloading package mte_teip5 to /root/nltk_data...\n",
      "       |   Unzipping corpora/mte_teip5.zip.\n",
      "       | Downloading package averaged_perceptron_tagger to\n",
      "       |     /root/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "       | Downloading package averaged_perceptron_tagger_ru to\n",
      "       |     /root/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
      "       | Downloading package perluniprops to /root/nltk_data...\n",
      "       |   Unzipping misc/perluniprops.zip.\n",
      "       | Downloading package nonbreaking_prefixes to\n",
      "       |     /root/nltk_data...\n",
      "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "       | Downloading package vader_lexicon to /root/nltk_data...\n",
      "       | Downloading package porter_test to /root/nltk_data...\n",
      "       |   Unzipping stemmers/porter_test.zip.\n",
      "       | Downloading package wmt15_eval to /root/nltk_data...\n",
      "       |   Unzipping models/wmt15_eval.zip.\n",
      "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "       |   Unzipping misc/mwa_ppdb.zip.\n",
      "       | \n",
      "     Done downloading collection all\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3A40BCcVFC8",
    "outputId": "6a4a1613-a95b-4430-a7ae-a21bcb93c3bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "import string\n",
    "punctuations = list(string.punctuation)\n",
    "stop.update(punctuations)\n",
    "\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "HHDwd4hba5go"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "bMPmq1IQaqxj"
   },
   "outputs": [],
   "source": [
    "def get_simple_tag(tag):\n",
    "  if (tag.startswith('J')):\n",
    "    return wordnet.ADJ\n",
    "  elif (tag.startswith('V')):\n",
    "    return wordnet.VERB\n",
    "  elif (tag.startswith('N')):\n",
    "    return wordnet.NOUN\n",
    "  elif (tag.startswith('R')):\n",
    "    return wordnet.ADV\n",
    "  else:\n",
    "    return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "A5vhi_GyWxb9"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_tweets(tweet):\n",
    "  clean_words = []\n",
    "  # print(tweet)\n",
    "  words = word_tokenize(tweet)\n",
    "  for word in words:\n",
    "    if word.lower() not in stop:\n",
    "      pos = pos_tag([word])\n",
    "      w = lemmatizer.lemmatize(word, pos = get_simple_tag(pos[0][1]))\n",
    "      clean_words.append(w.lower())\n",
    "\n",
    "  return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hrob8gJaTe9",
    "outputId": "49bd9cac-d728-4b38-c9cb-35d592c7c553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['americanair',\n",
       "  'sweetmel',\n",
       "  'weather',\n",
       "  'bad',\n",
       "  'would',\n",
       "  \"n't\",\n",
       "  'folk',\n",
       "  'try',\n",
       "  'extra',\n",
       "  'hard',\n",
       "  'communicate',\n",
       "  '...',\n",
       "  'load',\n",
       "  'bag',\n",
       "  'onto',\n",
       "  'flight',\n",
       "  '1320',\n",
       "  '...',\n",
       "  '...',\n",
       "  'anything'],\n",
       " ['americanair', 'yes', \"'s\", 'next', 'flight'],\n",
       " ['usairways',\n",
       "  'stuck',\n",
       "  'ramp',\n",
       "  'dca',\n",
       "  'us',\n",
       "  'air',\n",
       "  'computer',\n",
       "  'system',\n",
       "  'crashed',\n",
       "  '...',\n",
       "  'everywhere'],\n",
       " ['americanair',\n",
       "  'dotnetnate',\n",
       "  'two',\n",
       "  'hour',\n",
       "  'wait',\n",
       "  'exps',\n",
       "  'sit',\n",
       "  'jfk',\n",
       "  'phx',\n",
       "  'flight',\n",
       "  'us',\n",
       "  'computer',\n",
       "  'shot',\n",
       "  'lax',\n",
       "  'flight'],\n",
       " ['americanair',\n",
       "  'airport',\n",
       "  '8hrs',\n",
       "  'told',\n",
       "  'nothing',\n",
       "  'anyone',\n",
       "  'rep',\n",
       "  'say',\n",
       "  '``',\n",
       "  'wait',\n",
       "  'mechanic',\n",
       "  'finish',\n",
       "  'lunch',\n",
       "  \"''\"]]"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_tweets_list = [clean_tweets(tweet) for tweet in train_tweets_list]\n",
    "clean_train_tweets_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t28TD1Hcdwoy",
    "outputId": "4943fc77-235b-48fa-a440-27d42c9716b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['americanair', 'guy', 'intentionally', 'try', 'lose', 'customer', 'money'],\n",
       " ['jetblue', 'checked', 'yesterday', 'look', 'like', 'something', 'change'],\n",
       " ['southwestair', '5', 'min', 'away'],\n",
       " ['usairways',\n",
       "  'never',\n",
       "  'fly',\n",
       "  'u',\n",
       "  'airway',\n",
       "  'american',\n",
       "  'share',\n",
       "  'nightmare',\n",
       "  'story',\n",
       "  'many',\n",
       "  'others',\n",
       "  'know',\n",
       "  'fly'],\n",
       " ['united',\n",
       "  'shame',\n",
       "  \"'s\",\n",
       "  'flex',\n",
       "  'ticket',\n",
       "  'transfer',\n",
       "  'rule',\n",
       "  'even',\n",
       "  'call',\n",
       "  'neurosurgery',\n",
       "  'icu',\n",
       "  \"n't\",\n",
       "  'enough']]"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_tweets_list = [clean_tweets(tweet) for tweet in test_tweets_list]\n",
    "clean_test_tweets_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOTyflFUeWVn",
    "outputId": "7ced3cad-287e-4d38-eef6-8bfa716f479d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"americanair sweetmel weather bad would n't folk try extra hard communicate ... load bag onto flight 1320 ... ... anything\",\n",
       " \"americanair yes 's next flight\",\n",
       " 'usairways stuck ramp dca us air computer system crashed ... everywhere',\n",
       " 'americanair dotnetnate two hour wait exps sit jfk phx flight us computer shot lax flight',\n",
       " \"americanair airport 8hrs told nothing anyone rep say `` wait mechanic finish lunch ''\"]"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = [\" \".join(word) for word in clean_train_tweets_list]\n",
    "x_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oglq-BAGeyE9",
    "outputId": "6b24a857-36d1-46e5-e4e1-8f3d6790ee36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['americanair guy intentionally try lose customer money',\n",
       " 'jetblue checked yesterday look like something change',\n",
       " 'southwestair 5 min away',\n",
       " 'usairways never fly u airway american share nightmare story many others know fly',\n",
       " \"united shame 's flex ticket transfer rule even call neurosurgery icu n't enough\"]"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = [\" \".join(word) for word in clean_test_tweets_list]\n",
    "x_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Runo5Okd4_M",
    "outputId": "a62c0539-90a3-4cca-cb54-87ad24003e42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8235x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 93738 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(max_features = 5000, ngram_range=(1, 2))\n",
    "x_train_transformed = vec.fit_transform(x_train)\n",
    "x_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m53h0JXJfE39",
    "outputId": "403c73f2-c49b-41b6-cb32-7c277463aac6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000 mile',\n",
       " '03',\n",
       " '05',\n",
       " '10',\n",
       " '10 000',\n",
       " '10 30',\n",
       " '10 day',\n",
       " '10 hour',\n",
       " '10 hr',\n",
       " '10 min',\n",
       " '10 minute',\n",
       " '100',\n",
       " '100 people',\n",
       " '1000',\n",
       " '10pm',\n",
       " '11',\n",
       " '11 30',\n",
       " '11 hr',\n",
       " '12',\n",
       " '12 hour',\n",
       " '1230',\n",
       " '13',\n",
       " '130',\n",
       " '14',\n",
       " '140',\n",
       " '140 character',\n",
       " '15',\n",
       " '15 hour',\n",
       " '15 min',\n",
       " '15 minute',\n",
       " '150',\n",
       " '152',\n",
       " '15th',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '19',\n",
       " '1hr',\n",
       " '1hr delay',\n",
       " '1k',\n",
       " '1st',\n",
       " '1st class',\n",
       " '1st flight',\n",
       " '1st time',\n",
       " '20',\n",
       " '20 min',\n",
       " '20 minute',\n",
       " '200',\n",
       " '200 fee',\n",
       " '2014',\n",
       " '2015',\n",
       " '20min',\n",
       " '21',\n",
       " '22',\n",
       " '22 keep',\n",
       " '23',\n",
       " '24',\n",
       " '24 hour',\n",
       " '24 hr',\n",
       " '24h',\n",
       " '24hrs',\n",
       " '24th',\n",
       " '25',\n",
       " '25 min',\n",
       " '25 minute',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '28 tweet',\n",
       " '2day',\n",
       " '2hrs',\n",
       " '2nd',\n",
       " '2nd time',\n",
       " '2pm',\n",
       " '2x',\n",
       " '30',\n",
       " '30 60',\n",
       " '30 flight',\n",
       " '30 min',\n",
       " '30 minute',\n",
       " '300',\n",
       " '3056',\n",
       " '30a',\n",
       " '30am',\n",
       " '30min',\n",
       " '30pm',\n",
       " '3130',\n",
       " '32',\n",
       " '35',\n",
       " '35 min',\n",
       " '36',\n",
       " '39',\n",
       " '3am',\n",
       " '3hrs',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '3rd time',\n",
       " '3x',\n",
       " '40',\n",
       " '40 min',\n",
       " '40 minute',\n",
       " '400',\n",
       " '413',\n",
       " '42',\n",
       " '42 minute',\n",
       " '428',\n",
       " '428 4322',\n",
       " '4322',\n",
       " '44',\n",
       " '45',\n",
       " '45 min',\n",
       " '45 minute',\n",
       " '4567',\n",
       " '45min',\n",
       " '47',\n",
       " '48',\n",
       " '4pm',\n",
       " '4th',\n",
       " '50',\n",
       " '50 flight',\n",
       " '50 min',\n",
       " '50 minute',\n",
       " '50 people',\n",
       " '50 voucher',\n",
       " '500',\n",
       " '50am',\n",
       " '50k',\n",
       " '50pm',\n",
       " '51',\n",
       " '55',\n",
       " '59',\n",
       " '5hrs',\n",
       " '5th',\n",
       " '60',\n",
       " '60 min',\n",
       " '60 minute',\n",
       " '600',\n",
       " '699',\n",
       " '6am',\n",
       " '70',\n",
       " '700',\n",
       " '700 flight',\n",
       " '719',\n",
       " '728',\n",
       " '728 feb',\n",
       " '737',\n",
       " '747',\n",
       " '747 http',\n",
       " '75',\n",
       " '777',\n",
       " '787',\n",
       " '799',\n",
       " '7am',\n",
       " '7am flight',\n",
       " '7pm',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '800 428',\n",
       " '800 number',\n",
       " '80th',\n",
       " '85832',\n",
       " '85832 rock',\n",
       " '8am',\n",
       " '8aug',\n",
       " '8aug avgeek',\n",
       " '8pm',\n",
       " '90',\n",
       " '90 min',\n",
       " '90 minute',\n",
       " '99',\n",
       " 'a1',\n",
       " 'a320',\n",
       " 'aa',\n",
       " 'aa employee',\n",
       " 'aa flight',\n",
       " 'abc',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'able check',\n",
       " 'able get',\n",
       " 'aboard',\n",
       " 'abq',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'account help',\n",
       " 'acct',\n",
       " 'accurate',\n",
       " 'acknowledge',\n",
       " 'across',\n",
       " 'act',\n",
       " 'act together',\n",
       " 'action',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actually get',\n",
       " 'actually take',\n",
       " 'actually work',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'add flight',\n",
       " 'add ktn',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'address issue',\n",
       " 'addtl',\n",
       " 'admiral',\n",
       " 'admiral club',\n",
       " 'admit',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advisory',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'afford',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'age',\n",
       " 'agent',\n",
       " 'agent busy',\n",
       " 'agent flight',\n",
       " 'agent gate',\n",
       " 'agent get',\n",
       " 'agent give',\n",
       " 'agent help',\n",
       " 'agent phone',\n",
       " 'agent say',\n",
       " 'agent told',\n",
       " 'agents',\n",
       " 'ago',\n",
       " 'ago still',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahold',\n",
       " 'air',\n",
       " 'airbus',\n",
       " 'aircanada',\n",
       " 'aircraft',\n",
       " 'airfare',\n",
       " 'airline',\n",
       " 'airline cancelled',\n",
       " 'airline ever',\n",
       " 'airline flight',\n",
       " 'airline fly',\n",
       " 'airline get',\n",
       " 'airline ve',\n",
       " 'airline world',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airport hour',\n",
       " 'airport http',\n",
       " 'airport snow',\n",
       " 'airway',\n",
       " 'airways',\n",
       " 'airways corporation',\n",
       " 'alaska',\n",
       " 'alert',\n",
       " 'ali',\n",
       " 'all',\n",
       " 'alliance',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'almost hour',\n",
       " 'almost hr',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'already cancelled',\n",
       " 'already delayed',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'also delayed',\n",
       " 'alternate',\n",
       " 'although',\n",
       " 'always',\n",
       " 'always delayed',\n",
       " 'am',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'america',\n",
       " 'american',\n",
       " 'american air',\n",
       " 'american airlines',\n",
       " 'american http',\n",
       " 'americanair',\n",
       " 'americanair aa',\n",
       " 'americanair absolutely',\n",
       " 'americanair airport',\n",
       " 'americanair almost',\n",
       " 'americanair already',\n",
       " 'americanair also',\n",
       " 'americanair appreciate',\n",
       " 'americanair awesome',\n",
       " 'americanair bad',\n",
       " 'americanair bag',\n",
       " 'americanair believe',\n",
       " 'americanair best',\n",
       " 'americanair book',\n",
       " 'americanair ca',\n",
       " 'americanair call',\n",
       " 'americanair cancelled',\n",
       " 'americanair change',\n",
       " 'americanair check',\n",
       " 'americanair could',\n",
       " 'americanair customer',\n",
       " 'americanair delay',\n",
       " 'americanair dfwairport',\n",
       " 'americanair dm',\n",
       " 'americanair dmed',\n",
       " 'americanair do',\n",
       " 'americanair even',\n",
       " 'americanair finally',\n",
       " 'americanair first',\n",
       " 'americanair flight',\n",
       " 'americanair flt',\n",
       " 'americanair fly',\n",
       " 'americanair follow',\n",
       " 'americanair friend',\n",
       " 'americanair gate',\n",
       " 'americanair get',\n",
       " 'americanair give',\n",
       " 'americanair go',\n",
       " 'americanair good',\n",
       " 'americanair great',\n",
       " 'americanair guess',\n",
       " 'americanair guy',\n",
       " 'americanair help',\n",
       " 'americanair hey',\n",
       " 'americanair hi',\n",
       " 'americanair hold',\n",
       " 'americanair hope',\n",
       " 'americanair hopefully',\n",
       " 'americanair hour',\n",
       " 'americanair http',\n",
       " 'americanair idea',\n",
       " 'americanair keep',\n",
       " 'americanair kid',\n",
       " 'americanair know',\n",
       " 'americanair last',\n",
       " 'americanair let',\n",
       " 'americanair like',\n",
       " 'americanair line',\n",
       " 'americanair ll',\n",
       " 'americanair look',\n",
       " 'americanair lose',\n",
       " 'americanair love',\n",
       " 'americanair make',\n",
       " 'americanair merge',\n",
       " 'americanair might',\n",
       " 'americanair miss',\n",
       " 'americanair month',\n",
       " 'americanair need',\n",
       " 'americanair never',\n",
       " 'americanair new',\n",
       " 'americanair offer',\n",
       " 'americanair oh',\n",
       " 'americanair ok',\n",
       " 'americanair okay',\n",
       " 'americanair one',\n",
       " 'americanair pay',\n",
       " 'americanair phone',\n",
       " 'americanair plane',\n",
       " 'americanair please',\n",
       " 'americanair provide',\n",
       " 'americanair re',\n",
       " 'americanair really',\n",
       " 'americanair rebooked',\n",
       " 'americanair response',\n",
       " 'americanair right',\n",
       " 'americanair rude',\n",
       " 'americanair run',\n",
       " 'americanair say',\n",
       " 'americanair see',\n",
       " 'americanair seem',\n",
       " 'americanair sent',\n",
       " 'americanair seriously',\n",
       " 'americanair service',\n",
       " 'americanair sit',\n",
       " 'americanair sorry',\n",
       " 'americanair spent',\n",
       " 'americanair staff',\n",
       " 'americanair status',\n",
       " 'americanair still',\n",
       " 'americanair strand',\n",
       " 'americanair stuck',\n",
       " 'americanair sure',\n",
       " 'americanair take',\n",
       " 'americanair tell',\n",
       " 'americanair thank',\n",
       " 'americanair thanks',\n",
       " 'americanair think',\n",
       " 'americanair thought',\n",
       " 'americanair thx',\n",
       " 'americanair ticket',\n",
       " 'americanair told',\n",
       " 'americanair travel',\n",
       " 'americanair true',\n",
       " 'americanair try',\n",
       " 'americanair trying',\n",
       " 'americanair understand',\n",
       " 'americanair united',\n",
       " 'americanair us',\n",
       " 'americanair usairways',\n",
       " 'americanair ve',\n",
       " 'americanair wait',\n",
       " 'americanair want',\n",
       " 'americanair way',\n",
       " 'americanair well',\n",
       " 'americanair worry',\n",
       " 'americanair would',\n",
       " 'americanair wow',\n",
       " 'americanair yep',\n",
       " 'americanair yes',\n",
       " 'americanair yet',\n",
       " 'americanairlines',\n",
       " 'amex',\n",
       " 'among',\n",
       " 'among teen',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amp americanair',\n",
       " 'amp back',\n",
       " 'amp best',\n",
       " 'amp beyond',\n",
       " 'amp ca',\n",
       " 'amp call',\n",
       " 'amp change',\n",
       " 'amp crew',\n",
       " 'amp flight',\n",
       " 'amp found',\n",
       " 'amp gate',\n",
       " 'amp get',\n",
       " 'amp give',\n",
       " 'amp hold',\n",
       " 'amp miss',\n",
       " 'amp one',\n",
       " 'amp still',\n",
       " 'amp told',\n",
       " 'amp united',\n",
       " 'amp ve',\n",
       " 'amp want',\n",
       " 'ana',\n",
       " 'and',\n",
       " 'angry',\n",
       " 'anniversary',\n",
       " 'announce',\n",
       " 'announce delay',\n",
       " 'announcement',\n",
       " 'announcement make',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annricord',\n",
       " 'another',\n",
       " 'another airline',\n",
       " 'another airport',\n",
       " 'another day',\n",
       " 'another flight',\n",
       " 'another gate',\n",
       " 'another great',\n",
       " 'another hour',\n",
       " 'another plane',\n",
       " 'another reason',\n",
       " 'answer',\n",
       " 'answer 800',\n",
       " 'answer call',\n",
       " 'answer help',\n",
       " 'answer phone',\n",
       " 'answer question',\n",
       " 'anthony',\n",
       " 'anticipate',\n",
       " 'any',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyone else',\n",
       " 'anyone help',\n",
       " 'anyone phone',\n",
       " 'anything',\n",
       " 'anything else',\n",
       " 'anything help',\n",
       " 'anything would',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apologize',\n",
       " 'apologizes',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'app air',\n",
       " 'app say',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appease',\n",
       " 'appease passenger',\n",
       " 'apple',\n",
       " 'apple pay',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'appreciate response',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approve',\n",
       " 'approx',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aqjn4hwnac',\n",
       " 'aqjn4hwnac negotiate',\n",
       " 'are',\n",
       " 'area',\n",
       " 'argue',\n",
       " 'arizona',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrival',\n",
       " 'arrival time',\n",
       " 'arrive',\n",
       " 'arrives',\n",
       " 'arrives flytpa',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'ask question',\n",
       " 'asked',\n",
       " 'asleep',\n",
       " 'assign',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assume',\n",
       " 'atc',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlanta show',\n",
       " 'atlantic',\n",
       " 'atrocious',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attitude toward',\n",
       " 'august',\n",
       " 'aus',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'auto',\n",
       " 'auto rebooked',\n",
       " 'automate',\n",
       " 'automatically',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'available flight',\n",
       " 'avgeek',\n",
       " 'avgeek http',\n",
       " 'aviation',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'award',\n",
       " 'award ticket',\n",
       " 'award travel',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awesome flight',\n",
       " 'awesome thanks',\n",
       " 'awful',\n",
       " 'awkward',\n",
       " 'b4',\n",
       " 'b737',\n",
       " 'b737 700',\n",
       " 'ba',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'back airport',\n",
       " 'back back',\n",
       " 'back dm',\n",
       " 'back feature',\n",
       " 'back forth',\n",
       " 'back gate',\n",
       " 'back hold',\n",
       " 'back home',\n",
       " 'back late',\n",
       " 'back seat',\n",
       " 'back thru',\n",
       " 'backup',\n",
       " 'backup plan',\n",
       " 'bad',\n",
       " 'bad airline',\n",
       " 'bad customer',\n",
       " 'bad day',\n",
       " 'bad experience',\n",
       " 'bad flight',\n",
       " 'bad fly',\n",
       " 'bad get',\n",
       " 'bad service',\n",
       " 'bad thing',\n",
       " 'bad weather',\n",
       " 'bad would',\n",
       " 'badcustomerservice',\n",
       " 'badge',\n",
       " 'badly',\n",
       " 'badservice',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'bag airport',\n",
       " 'bag amp',\n",
       " 'bag back',\n",
       " 'bag check',\n",
       " 'bag checked',\n",
       " 'bag claim',\n",
       " 'bag come',\n",
       " 'bag delayed',\n",
       " 'bag deliver',\n",
       " 'bag drop',\n",
       " 'bag even',\n",
       " 'bag fee',\n",
       " 'bag finally',\n",
       " 'bag fit',\n",
       " 'bag flight',\n",
       " 'bag fly',\n",
       " 'bag go',\n",
       " 'bag http',\n",
       " 'bag load',\n",
       " 'bag lose',\n",
       " 'bag make',\n",
       " 'bag miss',\n",
       " 'bag need',\n",
       " 'bag onto',\n",
       " 'bag wait',\n",
       " 'bag would',\n",
       " 'bag yet',\n",
       " 'baggage',\n",
       " 'baggage claim',\n",
       " 'baggage fee',\n",
       " 'baggage lose',\n",
       " 'baggage office',\n",
       " 'baggage service',\n",
       " 'bahamas',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'bankrupt',\n",
       " 'bar',\n",
       " 'barbados',\n",
       " 'barely',\n",
       " 'base',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'bathroom',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'battle appease',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'bdl',\n",
       " 'beach',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'become 747',\n",
       " 'beer',\n",
       " 'begin',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'belize',\n",
       " 'belt',\n",
       " 'benefit',\n",
       " 'best',\n",
       " 'best airline',\n",
       " 'best customer',\n",
       " 'best flight',\n",
       " 'best friend',\n",
       " 'best part',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'big',\n",
       " 'big thanks',\n",
       " 'bill',\n",
       " 'bin',\n",
       " 'bird',\n",
       " 'birmingham',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'biz',\n",
       " 'black',\n",
       " 'blame',\n",
       " 'blame weather',\n",
       " 'blog',\n",
       " 'blue',\n",
       " 'bluemanity',\n",
       " 'bna',\n",
       " 'board',\n",
       " 'board flight',\n",
       " 'board plane',\n",
       " 'boarding',\n",
       " 'boarding flight',\n",
       " 'boarding group',\n",
       " 'boarding pas',\n",
       " 'boarding pass',\n",
       " 'boarding plane',\n",
       " 'boarding position',\n",
       " 'boarding procedure',\n",
       " 'boarding process',\n",
       " 'boarding time',\n",
       " 'boat',\n",
       " 'bogota',\n",
       " 'boise',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'book another',\n",
       " 'book award',\n",
       " 'book dragon',\n",
       " 'book flight',\n",
       " 'book new',\n",
       " 'book one',\n",
       " 'book online',\n",
       " 'book phone',\n",
       " 'book seat',\n",
       " 'book ticket',\n",
       " 'book via',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'booking problems',\n",
       " 'boot',\n",
       " 'booze',\n",
       " 'bos',\n",
       " 'bos dca',\n",
       " 'bos gt',\n",
       " 'boston',\n",
       " 'bostonlogan',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bought',\n",
       " 'bought ticket',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brandmance',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'bridge',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bring back',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'browser',\n",
       " 'brutal',\n",
       " 'bs',\n",
       " 'btw',\n",
       " 'buf',\n",
       " 'buffalo',\n",
       " 'bummer',\n",
       " 'bumped',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'business class',\n",
       " 'business day',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'bwi',\n",
       " 'c26',\n",
       " 'ca',\n",
       " 'ca afford',\n",
       " 'ca believe',\n",
       " 'ca book',\n",
       " 'ca change',\n",
       " 'ca check',\n",
       " 'ca dm',\n",
       " 'ca even',\n",
       " 'ca find',\n",
       " 'ca fly',\n",
       " 'ca get',\n",
       " 'ca help',\n",
       " 'ca online',\n",
       " 'ca reach',\n",
       " 'ca rebook',\n",
       " 'ca seem',\n",
       " 'ca take',\n",
       " 'ca use',\n",
       " 'ca wait',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cabo',\n",
       " 'cake',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'call 800',\n",
       " 'call back',\n",
       " 'call cancelled',\n",
       " 'call center',\n",
       " 'call customer',\n",
       " 'call day',\n",
       " 'call flight',\n",
       " 'call get',\n",
       " 'call help',\n",
       " 'call number',\n",
       " 'call say',\n",
       " 'call speak',\n",
       " 'call united',\n",
       " 'call volume',\n",
       " 'callback',\n",
       " 'called',\n",
       " 'caller',\n",
       " 'camera',\n",
       " 'can',\n",
       " 'can response',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancelled',\n",
       " 'cancelled flight',\n",
       " 'cancelled flightation',\n",
       " 'cancelled flightations',\n",
       " 'cancelled flighted',\n",
       " 'cancelled flighting',\n",
       " 'cancelled flightlation',\n",
       " 'cancelled flightlations',\n",
       " 'cancelled flightled',\n",
       " 'cancelled flightling',\n",
       " 'cancelled flights',\n",
       " 'cancun',\n",
       " 'cant',\n",
       " 'cant get',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'car seat',\n",
       " 'card',\n",
       " 'care',\n",
       " 'care customer',\n",
       " 'carousel',\n",
       " 'carrier',\n",
       " 'carrieunderwood',\n",
       " 'carry',\n",
       " 'carry on',\n",
       " 'carryon',\n",
       " 'carseat',\n",
       " 'cart',\n",
       " 'case',\n",
       " 'case id',\n",
       " 'cash',\n",
       " 'catch',\n",
       " 'catch flight',\n",
       " 'catering',\n",
       " 'cause',\n",
       " 'cause miss',\n",
       " 'cc',\n",
       " 'celebrate',\n",
       " 'cell',\n",
       " 'cell phone',\n",
       " 'cellphone',\n",
       " 'center',\n",
       " 'central',\n",
       " 'century',\n",
       " 'ceo',\n",
       " 'ceo battle',\n",
       " 'ceo seek',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'certificate',\n",
       " 'cessna',\n",
       " 'cessna become',\n",
       " 'chair',\n",
       " 'chairman',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'chance could',\n",
       " 'chance get',\n",
       " 'change',\n",
       " 'change award',\n",
       " 'change ca',\n",
       " 'change date',\n",
       " 'change earlier',\n",
       " 'change fee',\n",
       " 'change flight',\n",
       " 'change make',\n",
       " 'change name',\n",
       " 'change online',\n",
       " 'change reservation',\n",
       " 'change seat',\n",
       " 'change ticket',\n",
       " 'channel',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charge 200',\n",
       " 'charge 25',\n",
       " 'charge people',\n",
       " 'charity',\n",
       " 'charleston',\n",
       " 'charlotte',\n",
       " 'charlotte nc',\n",
       " 'charter',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheapflights',\n",
       " 'cheapflights farecompare',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'check bag',\n",
       " 'check baggage',\n",
       " 'check dm',\n",
       " 'check flight',\n",
       " 'check in',\n",
       " 'check online',\n",
       " 'check status',\n",
       " 'checked',\n",
       " 'checked bag',\n",
       " 'checked baggage',\n",
       " 'checked flight',\n",
       " 'checkin',\n",
       " 'checkin online',\n",
       " 'cheers',\n",
       " 'cheese',\n",
       " 'cherry',\n",
       " 'chi',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'child',\n",
       " 'cho',\n",
       " 'chocolate',\n",
       " 'chocolate flight',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'choose seat',\n",
       " 'chrome',\n",
       " 'cincy',\n",
       " 'circle',\n",
       " 'circumstance',\n",
       " 'city',\n",
       " 'city http',\n",
       " 'claim',\n",
       " 'claim number',\n",
       " 'claimed',\n",
       " 'clarification',\n",
       " 'clarify',\n",
       " 'class',\n",
       " 'class passenger',\n",
       " 'class seat',\n",
       " 'cle',\n",
       " 'clean',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'cleveland',\n",
       " 'click',\n",
       " 'client',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'cloud',\n",
       " 'clt',\n",
       " 'clt day',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'cmh',\n",
       " 'cmon',\n",
       " 'cnn',\n",
       " 'co',\n",
       " 'co aqjn4hwnac',\n",
       " 'coach',\n",
       " ...]"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgK24ansfN2t",
    "outputId": "2a6d56b1-c461-4873-ab7a-fa0fa6fbdca1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2745x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 29393 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_transformed = vec.transform(x_test)\n",
    "x_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1vYS8AZkmc4",
    "outputId": "c96efa04-d392-4dc1-b711-b7cb2fff9a4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7486338797814208"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs = -1, n_estimators = 1000)\n",
    "clf.fit(x_train_transformed, y_train)\n",
    "clf.score(x_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qSFFbEL2k3fn",
    "outputId": "91829a42-4177-4750-8de2-21bfce75092d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7744990892531877"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000);\n",
    "clf.fit(x_train_transformed, y_train)\n",
    "clf.score(x_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7C21yzulcx0",
    "outputId": "01108047-238c-40a0-da39-8b9c498cdbdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7224043715846995"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=13, weights='distance');\n",
    "clf.fit(x_train_transformed, y_train)\n",
    "clf.score(x_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nndZnlVmRxn",
    "outputId": "4b76af16-98ad-4f0a-8c65-7bbd09323350"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7628415300546448"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=0.04);\n",
    "clf.fit(x_train_transformed, y_train)\n",
    "clf.score(x_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "0mHr5RwGmuPk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "6CHpHNaUnJla"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Dense(32, activation='relu',input_shape=(5000,)),\n",
    "  Dropout(0.4),\n",
    "  Dense(16, activation='tanh'),\n",
    "  Dropout(0.4),\n",
    "  Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "A2zABvYPnrLS"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuDCFmX7n0mw",
    "outputId": "b6cd2089-8204-43c6-89d6-09423838e27c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 1.0053 - accuracy: 0.5719 - val_loss: 0.7754 - val_accuracy: 0.6350\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.7105 - accuracy: 0.6900 - val_loss: 0.5890 - val_accuracy: 0.7683\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.8062 - val_loss: 0.5429 - val_accuracy: 0.7847\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8553 - val_loss: 0.5444 - val_accuracy: 0.7902\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8770 - val_loss: 0.5809 - val_accuracy: 0.7862\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.9103 - val_loss: 0.6120 - val_accuracy: 0.7774\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2346 - accuracy: 0.9265 - val_loss: 0.6609 - val_accuracy: 0.7719\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9335 - val_loss: 0.7270 - val_accuracy: 0.7643\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1800 - accuracy: 0.9475 - val_loss: 0.7714 - val_accuracy: 0.7672\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9561 - val_loss: 0.8445 - val_accuracy: 0.7628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbcc1f5810>"
      ]
     },
     "execution_count": 159,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_transformed.todense(), y_train, epochs=10, batch_size=64, validation_data=(x_test_transformed.todense(), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-1RtxPR3JrG"
   },
   "source": [
    "We can see that after 4 epochs, it's overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moM6-ojQ39Cv",
    "outputId": "3df959c1-9e6a-4241-885b-e7ca7f5ef471"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_labelled = clf.predict(x_test_transformed)\n",
    "y_pred_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "ISjSzBs33RSN"
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for label in y_pred_labelled:\n",
    "  if (label == 0):\n",
    "    y_pred.append('negative')\n",
    "  elif (label == 1):\n",
    "    y_pred.append('positive')\n",
    "  else:\n",
    "    y_pred.append('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cyc6CZzw4tST",
    "outputId": "995e9bfe-6a43-42a2-ac8e-184426c05e17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " ...]"
      ]
     },
     "execution_count": 164,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "4y51lFd0lQF7"
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(\"TwitterPredictions.csv\", index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Twitter_Sentiment_Analysis_1 (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
